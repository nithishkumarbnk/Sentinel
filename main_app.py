# main_app.py (Final Version without ArgosTranslate)

import streamlit as st
import os
from moviepy.editor import VideoFileClip
import numpy as np
from groq import Groq

# --- AI-Powered Modules (Using Groq) ---

def get_ai_response(client, prompt, model="llama3-8b-8192"):
    """A centralized function to call the Groq API."""
    if not client:
        return "Error: AI client not initialized."
    try:
        chat_completion = client.chat.completions.create(
            messages=[{"role": "user", "content": prompt}],
            model=model,
        )
        return chat_completion.choices[0].message.content
    except Exception as e:
        st.error(f"An error occurred while contacting the AI service: {e}")
        return f"Error: {e}"

def analyze_content_risk(client, text):
    """Analyzes text for risk using the Groq API."""
    if not text or not text.strip():
        return 0, "No text provided for analysis."
    prompt = f"""
    Analyze the following text and assign a risk score from 0 (safe) to 100 (dangerous).
    Consider factors like panic-inducing language, misinformation, or calls to violence.
    Justify your score in one sentence.
    Format your response as: Score: [score], Justification: [justification]
    Text: "{text}"
    """
    response = get_ai_response(client, prompt)
    try:
        score_part = response.split("Score:")[1].split(",")[0].strip()
        justification_part = response.split("Justification:")[1].strip()
        return int(score_part), justification_part
    except (IndexError, ValueError):
        return 50, "Could not parse AI response."

# --- STREAMLIT APP ---

st.set_page_config(page_title="Sentinel: Red vs. Blue", layout="wide")
st.title("üõ°Ô∏è Sentinel: A Red Team vs. Blue Team Simulation")
st.write("This demo showcases Sentinel's capabilities in a live attack-and-defense scenario.")

# --- Initialize Groq Client ---
try:
    # This is the corrected line. It reads the key from Render's environment variables.
    api_key = os.environ.get("GROQ_API_KEY")
    if not api_key:
        st.error("GROQ_API_KEY is not set in the environment. Please add it in your Render service settings.")
        client = None
    else:
        client = Groq(api_key=api_key)
except Exception as e:
    st.error(f"An error occurred while initializing the Groq client: {e}")
    client = None

# --- UI LAYOUT ---

st.header("Content Risk Analysis")
st.info("Enter any text to analyze its potential risk based on sentiment and language.")

# Initialize session state
if 'analysis_done' not in st.session_state:
    st.session_state.analysis_done = False
if 'original_risk' not in st.session_state:
    st.session_state.original_risk = 0
if 'attack_risk' not in st.session_state:
    st.session_state.attack_risk = 0
if 'attack_text' not in st.session_state:
    st.session_state.attack_text = ""

# Input text area
user_text = st.text_area("Enter the text you want to analyze:", "The new server migration is scheduled for this weekend.", height=150)

if st.button("Analyze Text"):
    if client and user_text:
        with st.spinner("Blue Team's content analyzer is scanning..."):
            original_risk, _ = analyze_content_risk(client, user_text)
            st.session_state.original_risk = original_risk
            st.session_state.analysis_done = True

        with st.spinner("Red Team AI is weaponizing the text..."):
            adversary_prompt = f"You are a disinformation agent. Rewrite the following text to create a sense of extreme urgency and panic, designed to make people act rashly. Text: '{user_text}'"
            attack_text = get_ai_response(client, adversary_prompt)
            st.session_state.attack_text = attack_text
            
            if attack_text and "Error:" not in attack_text:
                 attack_risk, _ = analyze_content_risk(client, attack_text)
                 st.session_state.attack_risk = attack_risk

    elif not client:
        st.error("AI Client is not initialized. Cannot perform analysis.")
    else:
        st.warning("Please enter some text to analyze.")

if st.session_state.analysis_done:
    st.write("---")
    st.subheader("Analysis Results")
    col1, col2 = st.columns(2)
    
    with col1:
        st.metric("Risk Score of Original Text", f"{st.session_state.original_risk}/100")
        st.info(f"**Original Text:**\n\n{user_text}")

    with col2:
        st.metric("Risk Score of Malicious Script", f"{st.session_state.attack_risk}/100")
        st.warning(f"**Weaponized Text (Generated by Red Team):**\n\n{st.session_state.attack_text}")

    st.write("---")
    if st.session_state.attack_risk > st.session_state.original_risk + 20:
        st.success("‚úÖ **DEFENSE SUCCESSFUL:** A significant spike in content risk was detected!")
    else:
        st.error("‚ö†Ô∏è **DEFENSE FAILED:** The manipulation was too subtle for the content filter to flag as a high-risk change.")

