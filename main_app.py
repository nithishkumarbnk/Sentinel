# main_app.py (Final, Standalone Version for Render)

import streamlit as st
import os
from groq import Groq

# --- AI-Powered Functions (Self-Contained) ---

def get_ai_response(client, prompt, model="llama3-8b-8192"):
    """A centralized function to call the Groq API."""
    if not client:
        return "Error: AI client not initialized."
    try:
        chat_completion = client.chat.completions.create(
            messages=[{"role": "user", "content": prompt}],
            model=model,
        )
        # Correctly access the response content
        return chat_completion.choices[0].message.content
    except Exception as e:
        st.error(f"An error occurred while contacting the AI service: {e}")
        return f"Error: {e}"

def analyze_content_risk(client, text):
    """Analyzes text for risk using the Groq API."""
    if not text or not text.strip():
        return 0, "No text provided for analysis."
    prompt = f"""
    Analyze the following text and assign a risk score from 0 (safe) to 100 (dangerous).
    Consider factors like panic-inducing language, misinformation, or calls to violence.
    Justify your score in one sentence.
    Format your response as: Score: [score], Justification: [justification]
    Text: "{text}"
    """
    response = get_ai_response(client, prompt)
    try:
        # Robustly parse the response
        score_part = response.split("Score:")[1].split(",")[0].strip()
        justification_part = response.split("Justification:")[1].strip()
        return int(score_part), justification_part
    except (IndexError, ValueError):
        return 50, "Could not parse AI response."

# --- STREAMLIT APP CONFIGURATION ---

st.set_page_config(page_title="Sentinel: Content Risk Analyzer", layout="wide")
st.title("üõ°Ô∏è Sentinel: Content Risk Analyzer")
st.info("Enter text to analyze its risk. The Red Team AI will then attempt to weaponize it, and the Blue Team will assess the change in risk.")

# --- Initialize Groq Client ---
client = None
try:
    # This reads the key from Render's environment variables.
    api_key = os.environ.get("GROQ_API_KEY")
    if not api_key:
        st.error("GROQ_API_KEY is not set. Please add it in your Render service settings under the 'Environment' tab.")
    else:
        client = Groq(api_key=api_key)
except Exception as e:
    st.error(f"An error occurred while initializing the Groq client: {e}")

# --- UI LAYOUT ---

# Initialize session state to hold values between reruns
if 'analysis_done' not in st.session_state:
    st.session_state.analysis_done = False
    st.session_state.original_text = ""
    st.session_state.original_risk = 0
    st.session_state.attack_text = ""
    st.session_state.attack_risk = 0

# Input text area
user_text = st.text_area("Enter the text you want to analyze:", "The new server migration is scheduled for this weekend.", height=150)

if st.button("Analyze and Simulate Attack"):
    if client and user_text:
        st.session_state.original_text = user_text
        with st.spinner("Blue Team is analyzing the original text..."):
            original_risk, _ = analyze_content_risk(client, user_text)
            st.session_state.original_risk = original_risk
            st.session_state.analysis_done = True

        with st.spinner("Red Team AI is weaponizing the text..."):
            adversary_prompt = f"You are a disinformation agent. Rewrite the following text to create a sense of extreme urgency and panic, designed to make people act rashly. Text: '{user_text}'"
            attack_text = get_ai_response(client, adversary_prompt)
            st.session_state.attack_text = attack_text
            
            if attack_text and "Error:" not in attack_text:
                 with st.spinner("Blue Team is analyzing the weaponized text..."):
                    attack_risk, _ = analyze_content_risk(client, attack_text)
                    st.session_state.attack_risk = attack_risk

    elif not client:
        st.error("AI Client is not initialized. Cannot perform analysis.")
    else:
        st.warning("Please enter some text to analyze.")

# Display results only after the button has been clicked
if st.session_state.analysis_done:
    st.write("---")
    st.subheader("Analysis Results")
    col1, col2 = st.columns(2)
    
    with col1:
        st.metric("Risk Score of Original Text", f"{st.session_state.original_risk}/100")
        st.info(f"**Original Text:**\n\n{st.session_state.original_text}")

    with col2:
        st.metric("Risk Score of Malicious Script", f"{st.session_state.attack_risk}/100")
        st.warning(f"**Weaponized Text (Generated by Red Team):**\n\n{st.session_state.attack_text}")

    st.write("---")
    if st.session_state.attack_risk > st.session_state.original_risk + 20:
        st.success("‚úÖ **DEFENSE SUCCESSFUL:** A significant spike in content risk was detected!")
    else:
        st.error("‚ö†Ô∏è **DEFENSE FAILED:** The manipulation was too subtle for the content filter to flag as a high-risk change.")
